# MLOps Demo

A simple machine learning pipeline demo project.

<br/>

## Project Structure

```
mlops-demo/
├── data/
│   └── user_activity.csv       # Original CSV data
│   └── X.csv / y.csv          # Preprocessed input/target
│   └── scaler.pkl             # StandardScaler object for data scaling
├── model/
│   └── model.pkl              # Trained RandomForestClassifier model
├── preprocess.py              # Preprocessing script
├── train_model.py             # Training and saving script
├── predict_api.py             # FastAPI-based inference server
├── requirements.txt           # Dependencies
└── Dockerfile                 # Docker configuration
```

<br/>

## File Descriptions

### model.pkl
- File containing the saved RandomForestClassifier model
- Configured with n_estimators=100, random_state=42
- Saved using joblib.dump()
- Generated by running train_model.py in actual use

### scaler.pkl
- File containing the saved StandardScaler object
- Stores scaling parameters used in data preprocessing
- Saved using joblib.dump()
- Generated by running preprocess.py in actual use

<br/>

## Installation and Execution

<br/>

### 1. Local Environment Setup

1. Create and activate virtual environment:
```bash
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```
Result: The `(venv)` prompt appears, indicating the virtual environment is activated.

2. Install dependencies:
```bash
pip3 install -r requirements.txt
```
Result: Required packages are installed, showing installation progress.
```
Collecting numpy>=1.26.0
Collecting pandas>=2.1.0
Collecting scikit-learn>=1.3.2
...
Successfully installed numpy-1.26.0 pandas-2.1.0 scikit-learn-1.3.2 ...
```

3. Preprocess data:
```bash
python3 preprocess.py
```
Result: Data preprocessing completes and the following files are generated:
```
data/X.csv  # Preprocessed input data
data/y.csv  # Preprocessed target data
data/scaler.pkl  # Scaling parameters
```

4. Train model:
```bash
python3 train_model.py
```
Result: Model training completes and the following file is generated:
```
model/model.pkl  # Trained model
```
Training results are displayed:
```
Model Accuracy: 0.XX
Model saved to model/model.pkl
```

5. Run API server:
```bash
python3 predict_api.py
```
Result: FastAPI server starts and the following message is displayed:
```
INFO:     Started server process [xxxxx]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
```

6. Deactivate virtual environment:
```bash
deactivate
```
Result: The `(venv)` prompt disappears, indicating the virtual environment is deactivated.

### 2. Docker Setup

1. Build Docker image:
```bash
docker build -t mlops-demo .
```
Result: Docker image is built and the following message is displayed:
```
Sending build context to Docker daemon  XX.XXMB
Step 1/4 : FROM python:3.13-slim
...
Step 5/7 : RUN python preprocess.py && python train_model.py
Preprocessing completed:
- Training data: XX samples
- Test data: XX samples
- Features: ['session_duration', 'page_views', 'clicks', 'scroll_depth', 'time_on_site']
Model Accuracy: 0.XX
Model saved to model/model.pkl
...
Successfully built xxxxxxxxxxxx
Successfully tagged mlops-demo:latest
```

2. Run Docker container:
```bash
docker run -p 8000:8000 mlops-demo
```
Result: Docker container starts and FastAPI server runs:
```
INFO:     Started server process [1]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
```

**Note**: Data preprocessing and model training are automatically executed during Docker build, so you don't need to run `preprocess.py` and `train_model.py` separately.

<br/>

## API Usage

### 1. Single prediction (CSV file)
```bash
curl -X POST "http://localhost:8000/predict" -H "accept: application/json" -H "Content-Type: multipart/form-data" -F "file=@data/test.csv"
```
Result: Returns prediction results in JSON format:
```json
{
  "predictions": [0, 1, 0],
  "probabilities": [0.2, 0.8, 0.3]
}
```

**Note**: If using Docker, create test.csv first:
```bash
# Create test data file
echo "session_duration,page_views,clicks,scroll_depth,time_on_site
130,6,9,80,190
50,2,3,35,65
170,7,11,85,210" > test.csv

# Then use the file
curl -X POST "http://localhost:8000/predict" -H "accept: application/json" -H "Content-Type: multipart/form-data" -F "file=@test.csv"
```

**Important**: If test.csv is in the data/ folder, you need to either:
1. Change to the data directory first:
```bash
cd data/
curl -X POST "http://localhost:8000/predict" -H "accept: application/json" -H "Content-Type: multipart/form-data" -F "file=@test.csv"
```

2. Or use the full path from the project root:
```bash
curl -X POST "http://localhost:8000/predict" -H "accept: application/json" -H "Content-Type: multipart/form-data" -F "file=@data/test.csv"
```

### 2. Batch prediction (JSON)
```bash
curl -X POST "http://localhost:8000/predict_batch" -H "accept: application/json" -H "Content-Type: application/json" -d '[{"session_duration": 130, "page_views": 6, "clicks": 9, "scroll_depth": 80, "time_on_site": 190}]'
```
Result: Returns prediction results in JSON format:
```json
{
  "predictions": [1],
  "probabilities": [0.75]
}
```

### 3. Using Python requests library
```python
import requests
import pandas as pd

# Predict with CSV file
with open('test.csv', 'rb') as f:
    files = {'file': f}
    response = requests.post('http://localhost:8000/predict', files=files)
    print(response.json())

# Predict with JSON data
data = [{"session_duration": 130, "page_views": 6, "clicks": 9, "scroll_depth": 80, "time_on_site": 190}]
response = requests.post('http://localhost:8000/predict_batch', json=data)
print(response.json())
```

### 4. Using JavaScript/Fetch API
```javascript
// Predict with CSV file
const formData = new FormData();
formData.append('file', fileInput.files[0]);

fetch('http://localhost:8000/predict', {
    method: 'POST',
    body: formData
})
.then(response => response.json())
.then(data => console.log(data));

// Predict with JSON data
const data = [{"session_duration": 130, "page_views": 6, "clicks": 9, "scroll_depth": 80, "time_on_site": 190}];

fetch('http://localhost:8000/predict_batch', {
    method: 'POST',
    headers: {
        'Content-Type': 'application/json',
    },
    body: JSON.stringify(data)
})
.then(response => response.json())
.then(data => console.log(data));
```

### 5. Using Postman
1. **CSV file prediction**:
   - Method: POST
   - URL: `http://localhost:8000/predict`
   - Body: form-data
   - Key: `file` (File type)
   - Value: Select test.csv file

2. **JSON prediction**:
   - Method: POST
   - URL: `http://localhost:8000/predict_batch`
   - Body: raw (JSON)
   - Content: `[{"session_duration": 130, "page_views": 6, "clicks": 9, "scroll_depth": 80, "time_on_site": 190}]`

### 6. Using wget (CSV file)
```bash
wget --post-file=test.csv --header="Content-Type: multipart/form-data" http://localhost:8000/predict
```

### 7. Using HTTPie
```bash
# CSV file prediction
http -f POST localhost:8000/predict file@test.csv

# JSON prediction
http POST localhost:8000/predict_batch session_duration:=130 page_views:=6 clicks:=9 scroll_depth:=80 time_on_site:=190
```

### 8. Quick test with inline data (Docker friendly)
```bash
# Create test file and predict in one command
echo "session_duration,page_views,clicks,scroll_depth,time_on_site
130,6,9,80,190" > test.csv && curl -X POST "http://localhost:8000/predict" -H "accept: application/json" -H "Content-Type: multipart/form-data" -F "file=@test.csv"
```

<br/>

## API Documentation

FastAPI auto-generated documentation is available at:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc